{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from scipy.linalg import sqrtm\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring Path Variables for Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 2000 8000\n"
     ]
    }
   ],
   "source": [
    "path = \"data\\cars_train\"\n",
    "SIZE = 256\n",
    "paths = glob.glob(path + \"/*.jpg\") \n",
    "paths_subset = np.random.choice(paths, 8_000, replace=False)\n",
    "rand_idxs = np.random.permutation(8_000)\n",
    "train_index = rand_idxs[:6000] \n",
    "val_index = rand_idxs[6000:] \n",
    "results = paths_subset[rand_idxs]\n",
    "train = paths_subset[train_index]\n",
    "val = paths_subset[val_index]\n",
    "print(len(train), len(val), len(results))\n",
    "\n",
    "\n",
    "os.makedirs(\"land_data\",exist_ok=True)\n",
    "os.makedirs(\"coco_data\",exist_ok=True)\n",
    "os.makedirs(\"orig_coco_data\",exist_ok=True)\n",
    "os.makedirs(\"orig_land_data\", exist_ok = True)\n",
    "os.makedirs(\"cars_data\",exist_ok=True)\n",
    "os.makedirs(\"orig_cars_data\", exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data With Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE)),\n",
    "                transforms.RandomVerticalFlip(), \n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Resize((SIZE, SIZE))\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\") \n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...] / 50. - 1. \n",
    "        ab = img_lab[[1, 2], ...] / 110. \n",
    "        \n",
    "        return {'L': L, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloaders(batch_size=64, n_workers=0, pin_memory=True, **kwargs): \n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers, pin_memory=pin_memory)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 32 125\n"
     ]
    }
   ],
   "source": [
    "train_data = make_dataloaders(paths=train, split='train')\n",
    "val_data = make_dataloaders(paths=val, split='val')\n",
    "result_dl = make_dataloaders(paths=results, split='val')\n",
    "data = next(iter(train_data))\n",
    "print(len(train_data), len(val_data), len(result_dl))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False, innermost=False, outermost=False):\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_c is None:\n",
    "            input_c = nf\n",
    "        dc = nn.Conv2d(input_c, ni, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        dr = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        ur = nn.ReLU(True)\n",
    "        un = nn.BatchNorm2d(nf)\n",
    "        \n",
    "        if not innermost and not outermost:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [dr, dc, downnorm]\n",
    "            up = [ur, upconv, un]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [dr, dc]\n",
    "            up = [ur, upconv, un]\n",
    "            model = down + up\n",
    "        elif outermost:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1)\n",
    "            up = [ur, upconv, nn.Tanh()]\n",
    "            down = [dc]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, total_filters=64):\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(total_filters * 8, total_filters * 8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            unet_block = UnetBlock(total_filters * 8, total_filters * 8, submodule=unet_block, dropout=True)\n",
    "        endfilter = total_filters * 8\n",
    "        for _ in range(3):\n",
    "            unet_block = UnetBlock(endfilter // 2, endfilter, submodule=unet_block)\n",
    "            endfilter //= 2\n",
    "        self.model = UnetBlock(output_c, endfilter, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_c, total_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, total_filters, norm=False)]\n",
    "        model += [self.get_layers(total_filters * 2 ** i, total_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                          for i in range(n_down)]\n",
    "                                                  \n",
    "        model += [self.get_layers(total_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] \n",
    "                                                                                             \n",
    "        self.model = nn.Sequential(*model)                                                   \n",
    "        \n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): \n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]   \n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]       \n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if not target_is_real:\n",
    "            labels = self.fake_label\n",
    "        else:\n",
    "            labels = self.real_label\n",
    "        return labels.expand_as(preds)\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initialize(net, init='norm', gain=0.02):\n",
    "    \n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "        elif hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = weight_initialize(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModel(nn.Module):\n",
    "    def __init__(self, nG=None, lr_G=2e-4, lr_D=2e-4, \n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if nG:\n",
    "            self.nG = nG.to(self.device)\n",
    "        else:\n",
    "            self.nG = init_model(Unet(input_c=1, output_c=2, n_down=8, total_filters=64), self.device)\n",
    "        self.nD = init_model(Discriminator(input_c=3, n_down=3, total_filters=64), self.device)\n",
    "        self.GAN_loss = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1_loss = nn.L1Loss()\n",
    "        self.Gen_optimize = optim.Adam(self.nG.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.Disc_optimize = optim.Adam(self.nD.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    \n",
    "    def bD(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.nD(fake_image.detach())\n",
    "        self.Disc_fake = self.GAN_loss(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.nD(real_image)\n",
    "        self.Disc_real = self.GAN_loss(real_preds, True)\n",
    "        self.Disc_Loss = (self.Disc_fake + self.Disc_real) * 0.5\n",
    "        self.Disc_Loss.backward()\n",
    "    \n",
    "    def bG(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.nD(fake_image)\n",
    "        self.loss_G_GAN = self.GAN_loss(fake_preds, True)\n",
    "        self.Gen_L1 = self.L1_loss(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.Gen_Loss = self.loss_G_GAN + self.Gen_L1\n",
    "        self.Gen_Loss.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.nD.train()\n",
    "        self.grad_required(self.nD, True)\n",
    "        self.Disc_optimize.zero_grad()\n",
    "        self.bD()\n",
    "        self.Disc_optimize.step()\n",
    "        \n",
    "        self.nG.train()\n",
    "        self.grad_required(self.nD, False)\n",
    "        self.Gen_optimize.zero_grad()\n",
    "        self.bG()\n",
    "        self.Gen_optimize.step()\n",
    "    def grad_required(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def init_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.fake_color = self.nG(self.L)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_metrics():\n",
    "    Disc_Loss = AverageMeter()\n",
    "    Gen_Loss = AverageMeter()\n",
    "    \n",
    "    return {'Disc_Loss': Disc_Loss,\n",
    "            'Gen_Loss': Gen_Loss}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "def L2R(L, ab):\n",
    "    L, ab = (L + 1.) * 50. ,  ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "    \n",
    "def visualize(model, data, save=True):\n",
    "    model.nG.eval()\n",
    "    with torch.no_grad():\n",
    "        model.init_input(data)\n",
    "        model.forward()\n",
    "    model.nG.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake, real = L2R(L, fake_color), L2R(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "        \n",
    "def log_results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "def train_model(model, train_data, epochs, display_every=94):\n",
    "    data = next(iter(val_data)) \n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = loss_metrics()\n",
    "        i = 0                                  \n",
    "        for data in tqdm(train_data):\n",
    "            model.init_input(data) \n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0))\n",
    "            i += 1\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_data)}\")\n",
    "                log_results(loss_meter_dict) \n",
    "                visualize(model, data, save=False) \n",
    "        torch.save(model.state_dict(), 'checkpoint22.pt')\n",
    "\n",
    "model = GANModel()\n",
    "cl = GANModel()\n",
    "clf = GANModel()\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "  print('loading model')\n",
    "  cl.load_state_dict(torch.load('checkpoint21.pt'))\n",
    "  clf.load_state_dict(torch.load('checkpoint21.pt'))\n",
    "  model.load_state_dict(torch.load('checkpoint21.pt'))\n",
    "train_model(model, train_data, epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Visualizing Results of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualiz(model, data, save=True):\n",
    "    model.nG.eval()\n",
    "    with torch.no_grad():\n",
    "        model.init_input(data)\n",
    "        model.forward()\n",
    "    model.nG.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = L2R(L, fake_color)\n",
    "    real_imgs = L2R(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "data = next(iter(val_data))       \n",
    "display_every = 8\n",
    "\n",
    "loss_meter_dict = loss_metrics() \n",
    "i = 0\n",
    "\n",
    "for data in tqdm(val_data):\n",
    "    clf.init_input(data) \n",
    "    clf.optimize()\n",
    "    update_losses(clf, loss_meter_dict, count=data['L'].size(0)) \n",
    "    i += 1\n",
    "    if i % display_every == 0:\n",
    "        print(f\"Iteration {i}/{len(val_data)}\")\n",
    "        log_results(loss_meter_dict) \n",
    "        visualiz(clf, data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results of model into Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "def visual(model, data, save=True):\n",
    "    global count\n",
    "    model.nG.eval()\n",
    "    with torch.no_grad():\n",
    "        model.init_input(data)\n",
    "        model.forward()\n",
    "    model.nG.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = L2R(L, fake_color)\n",
    "    real_imgs = L2R(L, real_color)\n",
    "\n",
    "    for i in range(fake_imgs.shape[0]):\n",
    "        img1 = Image.fromarray((fake_imgs[i] * 255).astype(np.uint8))\n",
    "        img2 = Image.fromarray((real_imgs[i] * 255).astype(np.uint8))\n",
    "        img1.save(f'cars_data/{count}.png')\n",
    "        img2.save(f'orig_cars_data/{count}.png')\n",
    "        count+=1\n",
    "data = next(iter(result_dl))       \n",
    "display_every = 8\n",
    "for data in tqdm(result_dl):\n",
    "    cl.init_input(data) \n",
    "    cl.optimize()\n",
    "    visual(cl, data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fbe21fa5aa757505045beb3b9a34335dc22524575b79ce90e8d44d7f9b1060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
